{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer provide easily train or fine-tune transformer models\n",
    "<div>\n",
    "<img src=\"image/trainer1.png\" width=800>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the GLUE MRPC dataset using dynamic padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['sentence1', 'sentence2', 'label', 'idx'], 'validation': ['sentence1', 'sentence2', 'label', 'idx'], 'test': ['sentence1', 'sentence2', 'label', 'idx']}\n",
      "{'train': 3668, 'validation': 408, 'test': 1725}\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiyaoxue/miniconda3/envs/python3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "print(raw_datasets.column_names)\n",
    "print(raw_datasets.num_rows)\n",
    "print(raw_datasets)\n",
    "checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the model and training arguments before creating the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test-trainer\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_gpu_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can then pass everything to teh ***Trainer*** class and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqiyaoxue\u001b[0m (\u001b[33mqiyaoxue-university-of-pittsburgh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/data1/workspace/qiyaoxue/HuggingFace_Learning_Note/wandb/run-20241010_011139-52gnso5o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qiyaoxue-university-of-pittsburgh/huggingface/runs/52gnso5o' target=\"_blank\">test-trainer</a></strong> to <a href='https://wandb.ai/qiyaoxue-university-of-pittsburgh/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qiyaoxue-university-of-pittsburgh/huggingface' target=\"_blank\">https://wandb.ai/qiyaoxue-university-of-pittsburgh/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qiyaoxue-university-of-pittsburgh/huggingface/runs/52gnso5o' target=\"_blank\">https://wandb.ai/qiyaoxue-university-of-pittsburgh/huggingface/runs/52gnso5o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiyaoxue/miniconda3/envs/python3.10/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='290' max='290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [290/290 00:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=290, training_loss=0.31281146345467403, metrics={'train_runtime': 45.8426, 'train_samples_per_second': 400.064, 'train_steps_per_second': 6.326, 'total_flos': 824195380915200.0, 'train_loss': 0.31281146345467403, 'epoch': 5.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ***predict*** methdod allow us to get the predictions of our model on a whole dataset, the metrics can be computed based on the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.6088499 ,  1.5501962 ],\n",
      "       [ 2.1464198 , -1.6830001 ],\n",
      "       [ 1.8887107 , -1.7898929 ],\n",
      "       [-1.5972127 ,  1.5385838 ],\n",
      "       [ 1.774671  , -1.4977522 ],\n",
      "       [-1.5907019 ,  1.5072527 ],\n",
      "       [-1.5342594 ,  1.4334662 ],\n",
      "       [-1.4576026 ,  1.2536845 ],\n",
      "       [-1.5580225 ,  1.4583511 ],\n",
      "       [-1.5831745 ,  1.5435964 ],\n",
      "       [-1.5711699 ,  1.5502669 ],\n",
      "       [ 1.1144499 , -1.3078934 ],\n",
      "       [ 2.1658502 , -1.9159585 ],\n",
      "       [-1.3888607 ,  1.1904985 ],\n",
      "       [-1.6151892 ,  1.551818  ],\n",
      "       [ 1.1762064 , -1.4395137 ],\n",
      "       [-1.610661  ,  1.5660318 ],\n",
      "       [ 0.243424  , -0.82058716],\n",
      "       [-1.6221073 ,  1.5586569 ],\n",
      "       [-0.4881922 ,  0.12062579],\n",
      "       [ 1.7689115 , -1.564496  ],\n",
      "       [-1.5147029 ,  1.3050042 ],\n",
      "       [-0.516321  ,  0.12758185],\n",
      "       [-1.6041856 ,  1.5550395 ],\n",
      "       [-1.6243608 ,  1.5212587 ],\n",
      "       [ 2.0356233 , -1.7156696 ],\n",
      "       [-0.35949177, -0.04092238],\n",
      "       [-1.5880136 ,  1.5688571 ],\n",
      "       [-1.6031995 ,  1.43459   ],\n",
      "       [-1.4534153 ,  1.3573002 ],\n",
      "       [-0.19824354, -0.17132446],\n",
      "       [-1.6393604 ,  1.5679206 ],\n",
      "       [-1.5716143 ,  1.4417931 ],\n",
      "       [-1.5613914 ,  1.4924877 ],\n",
      "       [-1.5555547 ,  1.4478914 ],\n",
      "       [-1.589299  ,  1.552539  ],\n",
      "       [ 1.5955008 , -1.3704308 ],\n",
      "       [ 2.1773994 , -1.7625862 ],\n",
      "       [-0.6807611 ,  0.20824707],\n",
      "       [-1.5731004 ,  1.5583221 ],\n",
      "       [ 2.273347  , -1.7550527 ],\n",
      "       [-1.5611683 ,  1.5230646 ],\n",
      "       [ 1.2508705 , -1.4743775 ],\n",
      "       [ 1.9785236 , -1.1577759 ],\n",
      "       [-1.1006767 ,  0.755956  ],\n",
      "       [-1.5901697 ,  1.5153791 ],\n",
      "       [-1.2366942 ,  0.98514223],\n",
      "       [ 1.8595195 , -1.5786844 ],\n",
      "       [-1.6028364 ,  1.4933802 ],\n",
      "       [-1.0449036 ,  0.7980529 ],\n",
      "       [-1.083278  ,  0.7495486 ],\n",
      "       [-1.3934687 ,  1.169066  ],\n",
      "       [-1.5952743 ,  1.4704739 ],\n",
      "       [-1.5676899 ,  1.5452669 ],\n",
      "       [-1.5976679 ,  1.5185615 ],\n",
      "       [-1.5839249 ,  1.4709563 ],\n",
      "       [ 0.97797024, -1.2587848 ],\n",
      "       [-1.5956032 ,  1.5456091 ],\n",
      "       [-1.5886879 ,  1.5366445 ],\n",
      "       [-1.6156938 ,  1.4723963 ],\n",
      "       [ 0.77718186, -0.9895767 ],\n",
      "       [-1.2515132 ,  0.9763074 ],\n",
      "       [-1.6044761 ,  1.5639821 ],\n",
      "       [-1.5569702 ,  1.4660636 ],\n",
      "       [-1.5396421 ,  1.4123566 ],\n",
      "       [ 1.5060744 , -1.6147649 ],\n",
      "       [-1.5905287 ,  1.5489409 ],\n",
      "       [-1.5643864 ,  1.5332539 ],\n",
      "       [-0.28089646, -0.27828985],\n",
      "       [-1.5779151 ,  1.5047436 ],\n",
      "       [-1.1382139 ,  0.6670405 ],\n",
      "       [-0.53608733,  0.2173349 ],\n",
      "       [-1.5915654 ,  1.547446  ],\n",
      "       [-1.5062705 ,  1.3257043 ],\n",
      "       [-1.4757799 ,  1.3535483 ],\n",
      "       [-1.5988218 ,  1.4912341 ],\n",
      "       [ 0.45022964, -0.3949017 ],\n",
      "       [-1.5851182 ,  1.5518752 ],\n",
      "       [-1.5695498 ,  1.5376471 ],\n",
      "       [-1.5682155 ,  1.5416127 ],\n",
      "       [-1.5148239 ,  1.4581923 ],\n",
      "       [-1.6141818 ,  1.562756  ],\n",
      "       [-1.5695086 ,  1.541122  ],\n",
      "       [ 2.221551  , -1.7913036 ],\n",
      "       [-1.5644014 ,  1.4307612 ],\n",
      "       [ 2.304488  , -1.7114187 ],\n",
      "       [-1.5530219 ,  1.4196975 ],\n",
      "       [ 1.2534199 , -1.15962   ],\n",
      "       [-1.5905279 ,  1.3893225 ],\n",
      "       [-1.6146351 ,  1.5746369 ],\n",
      "       [-1.4382437 ,  1.1709847 ],\n",
      "       [-1.5879492 ,  1.5316052 ],\n",
      "       [-1.5786594 ,  1.5419791 ],\n",
      "       [-0.6734907 ,  0.3271776 ],\n",
      "       [-1.5373107 ,  1.4550581 ],\n",
      "       [-1.6197462 ,  1.5354276 ],\n",
      "       [ 1.6510694 , -1.3373781 ],\n",
      "       [-1.2493887 ,  0.9065663 ],\n",
      "       [-1.566638  ,  1.5271987 ],\n",
      "       [-1.5991448 ,  1.531228  ],\n",
      "       [-1.6275017 ,  1.5644202 ],\n",
      "       [ 0.461271  , -1.0366533 ],\n",
      "       [-1.6079093 ,  1.5629774 ],\n",
      "       [-1.6158108 ,  1.560869  ],\n",
      "       [-1.2487673 ,  0.98148453],\n",
      "       [-1.5598574 ,  1.5079635 ],\n",
      "       [-1.3127288 ,  0.9972814 ],\n",
      "       [ 1.6573927 , -1.4414018 ],\n",
      "       [ 2.0279217 , -1.6631542 ],\n",
      "       [-1.5758386 ,  1.4743025 ],\n",
      "       [-1.5713352 ,  1.508171  ],\n",
      "       [-1.2282634 ,  1.0856645 ],\n",
      "       [-0.30628592, -0.0883513 ],\n",
      "       [-1.6093911 ,  1.5537118 ],\n",
      "       [-1.5757576 ,  1.4389085 ],\n",
      "       [ 1.9759148 , -1.7655903 ],\n",
      "       [-1.545215  ,  1.456846  ],\n",
      "       [-1.6069928 ,  1.4983313 ],\n",
      "       [-1.6393819 ,  1.5324656 ],\n",
      "       [-1.5975136 ,  1.5780872 ],\n",
      "       [-1.5722334 ,  1.5358998 ],\n",
      "       [-1.2221618 ,  0.904945  ],\n",
      "       [ 1.4309978 , -0.9714185 ],\n",
      "       [-1.5857202 ,  1.5394226 ],\n",
      "       [-1.5921669 ,  1.5499607 ],\n",
      "       [-1.6196785 ,  1.5206453 ],\n",
      "       [-1.635347  ,  1.509345  ],\n",
      "       [ 1.72803   , -1.5155468 ],\n",
      "       [-1.590446  ,  1.5563285 ],\n",
      "       [-1.5867149 ,  1.5288602 ],\n",
      "       [-0.29019138, -0.24446371],\n",
      "       [-0.20393752,  0.02125166],\n",
      "       [-0.41889325,  0.10382493],\n",
      "       [ 1.8533977 , -1.2284577 ],\n",
      "       [-1.544137  ,  1.4615568 ],\n",
      "       [-1.5903488 ,  1.523354  ],\n",
      "       [ 1.7087398 , -1.643762  ],\n",
      "       [ 2.132536  , -1.9655102 ],\n",
      "       [-1.5918818 ,  1.565914  ],\n",
      "       [ 1.3239444 , -1.6960627 ],\n",
      "       [-1.6179368 ,  1.5653782 ],\n",
      "       [-1.4820014 ,  1.2864667 ],\n",
      "       [ 1.6555166 , -1.4814057 ],\n",
      "       [-1.6075643 ,  1.5267359 ],\n",
      "       [ 1.9249065 , -1.6406771 ],\n",
      "       [-1.0074869 ,  0.68020016],\n",
      "       [-1.6023939 ,  1.5633833 ],\n",
      "       [-0.70121324,  0.21816199],\n",
      "       [ 2.0127156 , -1.6593127 ],\n",
      "       [ 2.1984148 , -1.6277568 ],\n",
      "       [ 2.013083  , -1.664393  ],\n",
      "       [ 0.10282756, -0.58333963],\n",
      "       [ 0.00922994, -0.25798187],\n",
      "       [-1.6034979 ,  1.5471764 ],\n",
      "       [-1.5405897 ,  1.4816142 ],\n",
      "       [-1.5760692 ,  1.5320121 ],\n",
      "       [-1.6186222 ,  1.5428218 ],\n",
      "       [-1.0496598 ,  0.562572  ],\n",
      "       [-1.3495071 ,  1.1916198 ],\n",
      "       [-0.6924289 ,  0.35411182],\n",
      "       [-1.5756942 ,  1.4832425 ],\n",
      "       [-1.3087229 ,  1.009298  ],\n",
      "       [-1.5939186 ,  1.5503002 ],\n",
      "       [-1.587058  ,  1.5454714 ],\n",
      "       [-1.6009016 ,  1.5377207 ],\n",
      "       [-1.552832  ,  1.4466497 ],\n",
      "       [-1.5192143 ,  1.3508719 ],\n",
      "       [ 1.7684319 , -1.516525  ],\n",
      "       [-1.5949836 ,  1.533862  ],\n",
      "       [-0.7194764 ,  0.30780005],\n",
      "       [-1.3529091 ,  1.1463549 ],\n",
      "       [ 1.8747194 , -1.5554161 ],\n",
      "       [-1.4211934 ,  1.2173438 ],\n",
      "       [-1.6028945 ,  1.4429244 ],\n",
      "       [-0.83547837,  0.63999915],\n",
      "       [-1.6124604 ,  1.5164567 ],\n",
      "       [-1.5895526 ,  1.56193   ],\n",
      "       [ 1.7229487 , -1.507961  ],\n",
      "       [-1.6228626 ,  1.5679176 ],\n",
      "       [-1.5670062 ,  1.5441595 ],\n",
      "       [ 2.214471  , -1.8245467 ],\n",
      "       [ 0.22174476, -0.38123336],\n",
      "       [-1.5959245 ,  1.5566784 ],\n",
      "       [-1.5838169 ,  1.5484122 ],\n",
      "       [-1.3216166 ,  1.1516517 ],\n",
      "       [-1.5779097 ,  1.3349652 ],\n",
      "       [ 0.7809908 , -1.265215  ],\n",
      "       [-1.588402  ,  1.4793962 ],\n",
      "       [ 1.6166131 , -1.4226308 ],\n",
      "       [-1.5519224 ,  1.5382326 ],\n",
      "       [-1.579244  ,  1.4642019 ],\n",
      "       [ 1.0756258 , -1.6125474 ],\n",
      "       [ 1.675674  , -1.7053816 ],\n",
      "       [-1.5646423 ,  1.5430975 ],\n",
      "       [ 1.6753248 , -1.3976626 ],\n",
      "       [-1.4686404 ,  1.3702939 ],\n",
      "       [-1.5848868 ,  1.5556017 ],\n",
      "       [-1.3748802 ,  1.1674188 ],\n",
      "       [-1.6189173 ,  1.5122443 ],\n",
      "       [-1.5847411 ,  1.4604245 ],\n",
      "       [-1.5728966 ,  1.4878703 ],\n",
      "       [-1.6293651 ,  1.5564752 ],\n",
      "       [-1.4206477 ,  1.1232893 ],\n",
      "       [-0.4728769 ,  0.02681299],\n",
      "       [-1.2763125 ,  1.0351886 ],\n",
      "       [ 2.1876783 , -1.6461427 ],\n",
      "       [-1.5683175 ,  1.51535   ],\n",
      "       [-0.7778062 ,  0.58357173],\n",
      "       [-0.74479705,  0.37380925],\n",
      "       [-1.4095252 ,  1.2574787 ],\n",
      "       [ 1.8828961 , -1.4957002 ],\n",
      "       [-1.592496  ,  1.5509671 ],\n",
      "       [-1.5079406 ,  1.4048423 ],\n",
      "       [-1.1959875 ,  0.9343199 ],\n",
      "       [-1.5980705 ,  1.5306667 ],\n",
      "       [-1.5775255 ,  1.5457075 ],\n",
      "       [-1.6041749 ,  1.5142512 ],\n",
      "       [-1.5969092 ,  1.5480347 ],\n",
      "       [ 2.1062963 , -1.6201427 ],\n",
      "       [-1.2860773 ,  1.0862136 ],\n",
      "       [-1.4209915 ,  1.1979067 ],\n",
      "       [-1.5951816 ,  1.5080601 ],\n",
      "       [-1.6014606 ,  1.5355865 ],\n",
      "       [ 1.3575436 , -1.362481  ],\n",
      "       [-1.6241615 ,  1.5351694 ],\n",
      "       [-1.5905229 ,  1.559665  ],\n",
      "       [-1.5814086 ,  1.5547385 ],\n",
      "       [-1.5795512 ,  1.488769  ],\n",
      "       [-1.5753201 ,  1.4865105 ],\n",
      "       [-1.5708258 ,  1.4420307 ],\n",
      "       [-1.6078782 ,  1.575042  ],\n",
      "       [-1.5849271 ,  1.4121416 ],\n",
      "       [ 0.0769807 , -0.59552187],\n",
      "       [ 0.4516797 , -0.87105596],\n",
      "       [ 1.9018089 , -1.7917476 ],\n",
      "       [-1.4322358 ,  1.2365044 ],\n",
      "       [-0.95593494,  0.70527697],\n",
      "       [ 2.099487  , -1.6209065 ],\n",
      "       [-1.6352979 ,  1.5459198 ],\n",
      "       [ 1.5551876 , -1.3663856 ],\n",
      "       [-1.5447448 ,  1.441695  ],\n",
      "       [ 1.915161  , -1.5201519 ],\n",
      "       [-1.5882875 ,  1.4733579 ],\n",
      "       [-1.3090876 ,  1.0947529 ],\n",
      "       [-1.6235923 ,  1.5695735 ],\n",
      "       [-1.5647095 ,  1.4893254 ],\n",
      "       [-1.5707328 ,  1.4570341 ],\n",
      "       [-1.5432842 ,  1.4644728 ],\n",
      "       [-1.5184186 ,  1.3575805 ],\n",
      "       [-1.4013218 ,  1.2013932 ],\n",
      "       [-1.6052309 ,  1.4700816 ],\n",
      "       [-0.00481582, -0.4639804 ],\n",
      "       [-1.5316455 ,  1.4355228 ],\n",
      "       [-1.1780857 ,  0.86248785],\n",
      "       [ 1.9986701 , -1.8494687 ],\n",
      "       [ 1.6779155 , -1.4591324 ],\n",
      "       [-1.603417  ,  1.543195  ],\n",
      "       [-1.5685658 ,  1.5341266 ],\n",
      "       [-1.4756367 ,  1.2272832 ],\n",
      "       [ 1.6879607 , -1.4301922 ],\n",
      "       [-1.5992589 ,  1.458265  ],\n",
      "       [-1.6027262 ,  1.4731112 ],\n",
      "       [-1.5556077 ,  1.5002414 ],\n",
      "       [-1.514725  ,  1.3882499 ],\n",
      "       [-1.4786136 ,  1.3188262 ],\n",
      "       [-1.5270582 ,  1.4450275 ],\n",
      "       [-1.0574325 ,  0.76781   ],\n",
      "       [ 2.1070545 , -1.6132231 ],\n",
      "       [-1.2386689 ,  0.91459686],\n",
      "       [-1.5798392 ,  1.5156134 ],\n",
      "       [ 2.0714426 , -1.7021952 ],\n",
      "       [-1.5759745 ,  1.5430506 ],\n",
      "       [-1.6319286 ,  1.5071707 ],\n",
      "       [-1.6008713 ,  1.5678184 ],\n",
      "       [-1.6043463 ,  1.5592684 ],\n",
      "       [-1.4847531 ,  1.2972662 ],\n",
      "       [-0.85170233,  0.41915938],\n",
      "       [-1.4622633 ,  1.3147783 ],\n",
      "       [-1.5882707 ,  1.5247319 ],\n",
      "       [ 2.1280496 , -1.7291371 ],\n",
      "       [-1.5673897 ,  1.4840571 ],\n",
      "       [-1.5380474 ,  1.4796878 ],\n",
      "       [-1.4272275 ,  1.1608483 ],\n",
      "       [ 1.9591122 , -1.6275742 ],\n",
      "       [ 0.1707447 , -0.57009786],\n",
      "       [-1.617383  ,  1.5006953 ],\n",
      "       [-1.6040817 ,  1.5389702 ],\n",
      "       [-1.5344225 ,  1.4408591 ],\n",
      "       [ 0.6292884 , -0.72506374],\n",
      "       [-1.3018091 ,  1.0838782 ],\n",
      "       [ 1.9000721 , -1.6839716 ],\n",
      "       [ 1.9885921 , -1.5845908 ],\n",
      "       [-1.6608605 ,  1.5629593 ],\n",
      "       [-1.2481407 ,  0.9732232 ],\n",
      "       [-1.4455875 ,  1.2424555 ],\n",
      "       [ 1.9915053 , -1.5890269 ],\n",
      "       [ 1.900118  , -1.6391046 ],\n",
      "       [-1.4227891 ,  1.283722  ],\n",
      "       [-1.5622914 ,  1.5346553 ],\n",
      "       [ 0.8561291 , -0.46972626],\n",
      "       [-1.5894159 ,  1.5540359 ],\n",
      "       [-1.6184833 ,  1.5701426 ],\n",
      "       [-1.0865968 ,  0.7532791 ],\n",
      "       [ 0.76705474, -1.3242244 ],\n",
      "       [-1.5936192 ,  1.514482  ],\n",
      "       [-1.3856604 ,  1.2310569 ],\n",
      "       [ 2.018902  , -1.6254112 ],\n",
      "       [-1.6273317 ,  1.5476063 ],\n",
      "       [ 1.6059786 , -1.7990365 ],\n",
      "       [-1.0104867 ,  0.6288758 ],\n",
      "       [ 0.91308063, -1.4100213 ],\n",
      "       [-1.6214997 ,  1.5699415 ],\n",
      "       [-1.3241452 ,  0.9463136 ],\n",
      "       [ 1.5749092 , -1.3708086 ],\n",
      "       [-1.5774622 ,  1.5487376 ],\n",
      "       [-0.9169135 ,  0.5353727 ],\n",
      "       [-1.2982599 ,  1.0481671 ],\n",
      "       [-1.5764487 ,  1.5389405 ],\n",
      "       [ 1.7368364 , -1.5513613 ],\n",
      "       [ 0.5299335 , -0.91897655],\n",
      "       [-1.1672722 ,  0.8757139 ],\n",
      "       [ 1.681528  , -1.4143678 ],\n",
      "       [ 1.8400979 , -1.6160507 ],\n",
      "       [-0.7164904 ,  0.36056906],\n",
      "       [ 2.1867309 , -1.6517245 ],\n",
      "       [-1.5723197 ,  1.5485413 ],\n",
      "       [ 0.04653608, -0.54678065],\n",
      "       [-1.5913357 ,  1.5517086 ],\n",
      "       [-1.3837826 ,  1.148916  ],\n",
      "       [-1.5155069 ,  1.3605019 ],\n",
      "       [-1.6187018 ,  1.554499  ],\n",
      "       [-1.5944642 ,  1.5737125 ],\n",
      "       [-1.4751642 ,  1.3100647 ],\n",
      "       [-1.5877161 ,  1.5263581 ],\n",
      "       [-1.6021789 ,  1.5518463 ],\n",
      "       [-1.3879416 ,  1.1686448 ],\n",
      "       [-1.6364926 ,  1.5623575 ],\n",
      "       [-1.5802475 ,  1.5490083 ],\n",
      "       [ 2.0872693 , -1.6078073 ],\n",
      "       [-1.6130615 ,  1.544692  ],\n",
      "       [-1.591736  ,  1.5281786 ],\n",
      "       [-1.5653988 ,  1.4503276 ],\n",
      "       [ 1.9842472 , -1.6660423 ],\n",
      "       [ 0.9557287 , -1.3803874 ],\n",
      "       [-1.620731  ,  1.4962969 ],\n",
      "       [-1.5825933 ,  1.5323042 ],\n",
      "       [-1.6444279 ,  1.5479324 ],\n",
      "       [-1.5959235 ,  1.5506898 ],\n",
      "       [-1.3598093 ,  1.1425326 ],\n",
      "       [-1.581988  ,  1.5141402 ],\n",
      "       [ 1.6604226 , -1.2824996 ],\n",
      "       [-1.6118228 ,  1.5541211 ],\n",
      "       [-0.58667713,  0.21782386],\n",
      "       [-1.5856891 ,  1.5419029 ],\n",
      "       [ 1.949567  , -1.8921849 ],\n",
      "       [-1.4966483 ,  1.4003133 ],\n",
      "       [-1.5516282 ,  1.523524  ],\n",
      "       [ 1.9463359 , -1.568705  ],\n",
      "       [-1.5559145 ,  1.4525579 ],\n",
      "       [-1.5909568 ,  1.5001537 ],\n",
      "       [ 1.6569804 , -1.3500128 ],\n",
      "       [-1.5492367 ,  1.493284  ],\n",
      "       [-1.6284947 ,  1.5514238 ],\n",
      "       [-1.0213493 ,  0.6616124 ],\n",
      "       [-1.6332022 ,  1.5573865 ],\n",
      "       [-1.598703  ,  1.5638143 ],\n",
      "       [-1.6023334 ,  1.5227627 ],\n",
      "       [-1.3231474 ,  1.0875765 ],\n",
      "       [-1.2671859 ,  1.0183434 ],\n",
      "       [ 1.8162596 , -1.6789565 ],\n",
      "       [ 1.5952135 , -1.3174098 ],\n",
      "       [-1.6413594 ,  1.5589197 ],\n",
      "       [-0.21321036, -0.15891212],\n",
      "       [-1.522     ,  1.4398334 ],\n",
      "       [ 1.8877703 , -1.5468825 ],\n",
      "       [ 2.2630801 , -2.0067196 ],\n",
      "       [-1.5987617 ,  1.4629519 ],\n",
      "       [ 1.6122605 , -1.6050142 ],\n",
      "       [-1.5925071 ,  1.5344417 ],\n",
      "       [-1.6314157 ,  1.5123065 ],\n",
      "       [-1.6116306 ,  1.4854363 ],\n",
      "       [-1.5892919 ,  1.5304894 ],\n",
      "       [-1.4003856 ,  1.2023398 ],\n",
      "       [-1.5878749 ,  1.5599868 ],\n",
      "       [-1.5806656 ,  1.4764954 ],\n",
      "       [-1.5277771 ,  1.4235234 ],\n",
      "       [-0.9196363 ,  0.487281  ],\n",
      "       [ 1.9463195 , -1.51249   ],\n",
      "       [-1.56691   ,  1.5351585 ],\n",
      "       [-1.5668112 ,  1.4826263 ],\n",
      "       [-1.6148729 ,  1.5542821 ],\n",
      "       [-1.5200816 ,  1.4021049 ],\n",
      "       [-1.5843341 ,  1.4280701 ],\n",
      "       [-1.6370698 ,  1.510655  ],\n",
      "       [-1.5706965 ,  1.5328428 ],\n",
      "       [-1.5430484 ,  1.4268636 ],\n",
      "       [-1.5620953 ,  1.5328515 ],\n",
      "       [-1.3447428 ,  1.1100867 ],\n",
      "       [-1.5823342 ,  1.5126821 ],\n",
      "       [-1.6136328 ,  1.5181937 ],\n",
      "       [ 1.9670863 , -1.7778113 ],\n",
      "       [-1.5771831 ,  1.5414773 ],\n",
      "       [-1.5431529 ,  1.3228523 ],\n",
      "       [ 1.5823284 , -1.3560238 ],\n",
      "       [-1.5023087 ,  1.4430255 ],\n",
      "       [-1.5798286 ,  1.5383818 ],\n",
      "       [ 1.9566916 , -1.9773853 ],\n",
      "       [-0.6658431 ,  0.21945609]], dtype=float32), label_ids=array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), metrics={'test_loss': 0.4512815773487091, 'test_runtime': 0.4126, 'test_samples_per_second': 988.777, 'test_steps_per_second': 16.964})\n",
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions)\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8357843137254902, 'f1': 0.8854700854700854}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"glue\", \"mrpc\")\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To monitor metrics during training, we need to define a compute_metrics function and pass it to the ***Trainer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"glue\", \"mrpc\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test-trainer\", evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    TrainingArguments=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
